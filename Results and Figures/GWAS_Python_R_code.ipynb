{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac245a3",
   "metadata": {},
   "source": [
    "# GWAS Data Analysis Part\n",
    "In this section how to data analysis is done during this study are shown. During this analysis some part of the this analysis is run on Python and rest of them is run on R studio. All the necessary libraries install to use R program on Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('~/lastversion_gwas_analysis/PermGWAS_Scripts/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda66154",
   "metadata": {},
   "source": [
    "python code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98d6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fd7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rpy2\n",
    "%load_ext rpy2.ipython\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76681f",
   "metadata": {},
   "source": [
    "## GWAS functions are run \n",
    "f95_gwas (stored as f95_gwas.r) is a necessary function to load genotypic files, kinship file, to run GWAS funtions (gwas.r, emma.r, plots_gwas.r are download from https://github.com/arthurkorte/GWAS), and save output gwas files and plots is written by Arthur Korte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6469d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "f95_gwas<-function(Y,n=2,X.folder='~/lastversion_gwas_analysis/F_95',K.file='~/lastversion_gwas_analysis/F_95/K_F95.rda',incl.lm=FALSE,incl.beta=FALSE,update.snps=FALSE,save.output=T,out.format='rda',generate.plot=T,pre=colnames(Y)[n]) {\n",
    "\n",
    "load(K.file)\n",
    "\n",
    "  for ( u in 1:6) {\n",
    "\n",
    "  filename<-paste(X.folder,'/X_f95_',u,'.rda',sep='')\n",
    "\n",
    "  load(filename)\n",
    "  if (u==1) {\n",
    "    results<-amm_gwas(Y,X,K,m=n,include.lm=incl.lm,calculate.effect.size=incl.beta,update.top_snps=update.snps)\n",
    "  rm(X)\n",
    "  } else {\n",
    "\n",
    "\n",
    "  output<-amm_gwas(Y,X,K,m=n,include.lm=incl.lm,calculate.effect.size=incl.beta,update.top_snps=update.snps)\n",
    "  results<-rbind(results,output)\n",
    "  rm(X)\n",
    "  }\n",
    "\n",
    "  }\n",
    "\n",
    "#return(results)\n",
    "\n",
    "if (save.output==T) {\n",
    "  auto<-0\n",
    "  if (('rda'%in%out.format)==T) {\n",
    "name1<-paste(colnames(Y)[n],pre,'gwasf95.rda',sep='_')\n",
    "save(results,file=name1)\n",
    "auto<-1\n",
    "  }\n",
    "  if (('csv'%in%out.format)==T) {\n",
    "    name1b<-paste(colnames(Y)[n],pre,'gwasf95.csv',sep='_')\n",
    "    write.csv(results,file=name1b,row.names=FALSE)\n",
    "    auto<-1\n",
    "  }\n",
    "  if(auto==0){\n",
    "    cat('wrong output format to save the data specified','\\n')}\n",
    "}\n",
    "if (generate.plot==T) {\n",
    " name2<-paste(colnames(Y)[n],pre,'gwasf95.pdf',sep='_')\n",
    " name3<-paste(colnames(Y)[n],pre,sep='_')\n",
    "pdf(file=name2)\n",
    "plot_gwas(results,maf_or_mac=2,mac=5,name=name3)\n",
    "dev.off()\n",
    "}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd1e23",
   "metadata": {},
   "source": [
    "In this part, phenotypic files are read and put in a list. SLURM array are used to analysis all the phenotypic values on parallele to reduce time cost. After finishing analsis, renamed all the filename  and gwas result save as phenotypic file name (GWAS_f95_slurm.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c14bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "i <- as.numeric(Sys.getenv(\"SLURM_ARRAY_TASK_ID\"))\n",
    "##Load libraries and sources that are needed for reading files and creating a list\n",
    "library(tidyverse)\n",
    "library(fs)\n",
    "setwd(\"~/lastversion_gwas_analysis/F_95/\")\n",
    "source(\"gwas.r\") \n",
    "source(\"emma.r\")\n",
    "source(\"plots_gwas.r\")\n",
    "source('~/lastversion_gwas_analysis/f95_gwas.r')\n",
    "\n",
    "##Creating an empty list and put all phenotype file in this list\n",
    "setwd(\"~/lastversion_gwas_analysis/Over_Occ/Over_Coocurrence/\") #phenotype files folder \n",
    "Y <- list()\n",
    "csvfiles<-list.files(pattern = \"*.csv\")\n",
    "print(csvfiles[i])\n",
    "Y[[i]] <- read.csv(file = csvfiles[i])\n",
    "Y[[i]][, 1] <- as.numeric(Y[[i]][, 1])\n",
    "Y[[i]][, 2] <- as.numeric(Y[[i]][, 2])\n",
    "\n",
    "##Rewrite the same filename \n",
    "Y <- lapply(csvfiles, function(x) {\n",
    "  file <- read.csv(x)\n",
    "  # Get the start of filename prefix \n",
    "  prefix = gsub(\"_.*\", \"\", x)\n",
    "  # Get the suffix number\n",
    "  suffix = gsub(\".csv*\", \"\", x)  \n",
    "  colnames(file) <- paste(colnames(file), suffix, sep='_')\n",
    "  return(file)\n",
    "})\n",
    "\n",
    "##Gwas is running for each phenotype file with \"f95_gwas\" fuction\n",
    "f95_gwas(Y[[i]],pre=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee90ab",
   "metadata": {},
   "source": [
    "This is an alternatif if it can access SLURM scheduler it run all the phenotypic files in a loop so, using this one consume too much time (GWAS_f952.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "###Load libraries that are needed for .csv file reading and creating list\n",
    "##Load libraries and sources that are needed for reading files and creating a list\n",
    "library(tidyverse)\n",
    "library(fs)\n",
    "setwd(\"~/lastversion_gwas_analysis/F_95/\")\n",
    "source(\"gwas.r\") \n",
    "source(\"emma.r\")\n",
    "source(\"plots_gwas.r\")\n",
    "source('~/lastversion_gwas_analysis/f95_gwas.r')\n",
    "\n",
    "csvfiles <-\n",
    "  dir(path = \"~/lastversion_gwas_analysis/Over_Occ/Over_Coocurrence/\",\n",
    "      pattern = \".csv\",\n",
    "      full.names = TRUE)\n",
    "\n",
    "##Creating an empty list and put all phenotype file in this list\n",
    "Y <- list()\n",
    "for (i in seq_along(csvfiles)) {\n",
    "  Y[[i]] <- read.csv(file = csvfiles[i])\n",
    "  Y[[i]][, 1] <- as.numeric(Y[[i]][, 1])\n",
    "  Y[[i]][, 2] <- as.numeric(Y[[i]][, 2])\n",
    "}\n",
    "\n",
    "Y<-set_names(Y,csvfiles )\n",
    "\n",
    "##Gwas is running for each phenotype file with \"f95_gwas\" fuction\n",
    "for (i in seq_along(csvfiles)) {\n",
    "  f95_gwas(Y[[i]],pre=i)\n",
    "}\n",
    "saveRDS(csvfiles, file=\"phenotype_list.Rds\") #save the list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce0a9c8",
   "metadata": {},
   "source": [
    "## Counting number of rows for phenotype files: Filter length<50 and MPC<5\n",
    "In this section input of GWAS phenotype files is filtered. Phenotype files have been created on the basis of premature stop codons. These files have been created according to significant over cooccurrence of the two premature stop codons by Laura Steinmann (You can find the details of this work at https://github.com/laurasteinmann/Premature_Stop_Codons). The first premature stop codon was found in all accessions, and the phenotype value was determined according to the status of the second stop codon. The phenotypic value was coded as 1 if the first and second premature stop codons were formed at the same time, and 0 if there was only the first premature stop codon. As it seen in file names table df, first and second premature stop codons separated by underscore. This names are given according to which chromosome and which location this premature stop codon occured. In filename AT3G32920_AT2G16380.csv, in this file first premature stop codon occurred located 32920 region at chromosome 3, if second premature stop codon exist in that accesion is occured located 16380 region at chromosome 2. In this given AT3G32920_AT2G16380.csv phenotype file, 88 first premature stop codon AT3G32920 were found in this region, while only 16 second premature stop codon AT2G16380 were found in this region. This means that 16 accessions have had significant over cooccurance premature stop codon.\n",
    "\n",
    "Phenotype file_names are put into first column of dataframe called as df. Phenotype file\"s cloumn names were labeled accessions id and phenotype value as mentioned on above. Phenotype values are given 1 and 0 values, if there is an SNPs in this accession it represents 1, if there are no SNPs in that accession id it is given 0. After that number of rows (phenotype_length), number of SNPs (sum of rows), and non_SNPs (number of non SNPs) are counted and put in this df dataframe as new columns.\n",
    "\n",
    "Although these generated phenotype files were filtered and significant ones were found as a result, prefiltering steps are still important. This is because GWAS results are expected to establish a really significant relationship between SNPs and phenotype. For the remainder of the study, SNPs were termed significant over coorrunce premature stop codon. First, min_value or MPC (Minnor phenotype count, second most found phenotype counted), MPC less than 5 (min_value) are shown as 1. As a second step, the length of the phenotype files with less than 50 accessions (phe_length<50) are shown as 1. In this way, file names with min_value or phe_length 1 are determined, put in a new list and discarded as a result of the prefilter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ccd105a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>Phenotype_length</th>\n",
       "      <th>ko</th>\n",
       "      <th>non_ko</th>\n",
       "      <th>MPC</th>\n",
       "      <th>MPC&lt;5</th>\n",
       "      <th>Phe_length&lt;50</th>\n",
       "      <th>MPC&lt;5_or_Phe_length&lt;50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT3G32920_AT2G16380.csv</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "      <td>72</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT1G42680_AT5G63630.csv</td>\n",
       "      <td>135</td>\n",
       "      <td>32</td>\n",
       "      <td>103</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT4G00970_AT3G28610.csv</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT5G33280_AT5G03830.csv</td>\n",
       "      <td>97</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G42680_AT3G45740.csv</td>\n",
       "      <td>135</td>\n",
       "      <td>24</td>\n",
       "      <td>111</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>AT2G15930_AT4G15950.csv</td>\n",
       "      <td>311</td>\n",
       "      <td>25</td>\n",
       "      <td>286</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>AT1G01695_AT2G15930.csv</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>AT5G03830_AT5G33280.csv</td>\n",
       "      <td>331</td>\n",
       "      <td>70</td>\n",
       "      <td>261</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>AT2G16380_AT3G32920.csv</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>AT1G13430_AT2G41710.csv</td>\n",
       "      <td>57</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    File_name Phenotype_length  ko non_ko   MPC  MPC<5  \\\n",
       "0     AT3G32920_AT2G16380.csv               88  16     72  16.0      0   \n",
       "1     AT1G42680_AT5G63630.csv              135  32    103  32.0      0   \n",
       "2     AT4G00970_AT3G28610.csv               50  37     13  13.0      0   \n",
       "3     AT5G33280_AT5G03830.csv               97  70     27  27.0      0   \n",
       "4     AT1G42680_AT3G45740.csv              135  24    111  24.0      0   \n",
       "...                       ...              ...  ..    ...   ...    ...   \n",
       "1123  AT2G15930_AT4G15950.csv              311  25    286  25.0      0   \n",
       "1124  AT1G01695_AT2G15930.csv               43   3     40   3.0      1   \n",
       "1125  AT5G03830_AT5G33280.csv              331  70    261  70.0      0   \n",
       "1126  AT2G16380_AT3G32920.csv               21  16      5   5.0      0   \n",
       "1127  AT1G13430_AT2G41710.csv               57  16     41  16.0      0   \n",
       "\n",
       "      Phe_length<50  MPC<5_or_Phe_length<50  \n",
       "0                 0                     0.0  \n",
       "1                 0                     0.0  \n",
       "2                 0                     0.0  \n",
       "3                 0                     0.0  \n",
       "4                 0                     0.0  \n",
       "...             ...                     ...  \n",
       "1123              0                     0.0  \n",
       "1124              1                     1.0  \n",
       "1125              0                     0.0  \n",
       "1126              1                     1.0  \n",
       "1127              0                     0.0  \n",
       "\n",
       "[1128 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('~/lastversion_gwas_analysis/Over_Occ/Over_Coocurrence/')\n",
    "df = pd.DataFrame(columns=('File_name', 'Phenotype_length'))\n",
    "\n",
    "for index,i in enumerate(os.listdir('.')):\n",
    "    df.loc[index] = [i,len(pd.read_csv(i).index)]\n",
    "\n",
    "array=[]\n",
    "for file_to_read in glob.glob(\"*.csv\"):\n",
    "    df2 = pd.read_csv(file_to_read)\n",
    "    a=df2[\"Phenotype\"].sum()\n",
    "    array.append(a)\n",
    "b=pd.DataFrame(array)\n",
    "df[\"ko\"]=b\n",
    "\n",
    "###add new column as non_SNPs, \n",
    "df[\"non_ko\"]=df[\"Phenotype_length\"]-df[\"ko\"]\n",
    "#f\n",
    "##add new column min SNPs or non_SNPs\n",
    "df['MPC'] = df[['ko','non_ko']].min(axis=1)\n",
    "#f\n",
    "##add new column min_value<5 or phenotype_length<50\n",
    "df[\"MPC<5\"]=np.where(df['MPC'] <5, 1, 0)\n",
    "df[\"Phe_length<50\"]=np.where(df['Phenotype_length'] <50, 1, 0)\n",
    "df.loc[(df['MPC'] < 5)  | (df['Phenotype_length'] <50), 'MPC<5_or_Phe_length<50'] = 1\n",
    "df.loc[(df['MPC'] >= 5) & (df['Phenotype_length'] >=50), \"MPC<5_or_Phe_length<50\"] = 0\n",
    "df\n",
    "##save as .csv file\n",
    "#df.to_csv('/home/s417377/lastversion_gwas_analysis/Over_Occ/summary_file.csv', index=False)\n",
    "##find the file_name min<5_or_phe_length<50==1 and discard from folder, continue to next step rest of the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313b7f35",
   "metadata": {},
   "source": [
    "### Filtered files the file_name min<5_or_phe_length<50==0 \n",
    "In this step , files which does not discarded are put into new dataframe and saved. After next steps it will continue with these non-discarded files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4bbe7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6       AT2G41710_AT4G15950.csv\n",
       "7       AT1G01695_AT5G20450.csv\n",
       "9       AT2G16380_AT1G29710.csv\n",
       "10      AT1G01695_AT2G27340.csv\n",
       "18      AT1G65110_AT2G42730.csv\n",
       "                 ...           \n",
       "1118    AT2G16380_AT2G41470.csv\n",
       "1119    AT3G45740_AT2G16380.csv\n",
       "1121    AT5G51795_AT2G04845.csv\n",
       "1124    AT1G01695_AT2G15930.csv\n",
       "1126    AT2G16380_AT3G32920.csv\n",
       "Name: file_name, Length: 390, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('~/lastversion_gwas_analysis/Over_Occ/')\n",
    "filtered_files=filtered_files[\"file_name\"]\n",
    "filtered_files\n",
    "filtered_files.to_csv('/home/s417377/PermGWAS/input_list.csv', index=False,  header=False)\n",
    "#####find the file_name min<5_or_phe_length<50==1 and discard from folder, continue to next step to rest of the files\n",
    "discard_file=(df.loc[df['min<5_or_phe_length<50'] == 1])\n",
    "discard_file=discard_file[\"file_name\"]\n",
    "#discard_file.to_csv('/home/s417377/lastversion_gwas_analysis/Over_Occ/discard_files.csv', index=False, header=False)\n",
    "discard_file\n",
    "\n",
    "###discard files from discardfile.csv\n",
    "path = ('/home/s417377/lastversion_gwas_analysis/Over_Occ/Over_Occ_permutation/')\n",
    "os.chdir(path)\n",
    "with open('discard_files.csv', \"r\") as list_file:\n",
    "    _list = list_file.read().splitlines()\n",
    "    [os.remove(os.path.join(path,f)) for f in _list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dae43d",
   "metadata": {},
   "source": [
    "#### MAC>5  Filter\n",
    "In this part, MAC (Minnor Allele Cound) value is less than 5 is discarded from insdide of the all files and saved. Minnor Allele Count is the second most found allel in a population, studies showed that it has a major affect on traits (). The rest of the steps are continue with this new filtered files (mac_maf.r).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d022370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(tidyverse)\n",
    "library(fs)\n",
    "setwd(\"~/lastversion_gwas_analysis/Over_Occ/Over_Coocurrence/\")\n",
    "######filter for  mac>5\n",
    "Y <- list()\n",
    "GWAS_F95 <- list.files(pattern = \".rda\")\n",
    "dd<-grep(\".rda\", list.files(), value=T)\n",
    "d<-data.matrix(dd)\n",
    "for (i in 1:length((d))){\n",
    "    yyz<-load(d[i])\n",
    "    R<-subset(results, results$MAC>5 )\n",
    "    write.csv(R, file=paste( d[i],\"f95_small\",\".csv\", sep=\"\"))\n",
    "}\n",
    "##change files names:\n",
    "folder = \"~/lastversion_gwas_analysis/new/Over_Coocurrence/\"\n",
    "files <- list.files(folder,pattern = \"f95_.*.csv\",full.names = T) \n",
    "sapply(files,FUN=function(eachPath){ \n",
    "  file.rename(from=eachPath,to= sub(pattern=\"f95_\", paste0(\"\"),eachPath))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63263d6c",
   "metadata": {},
   "source": [
    "#### Stringent Bonferroni Correction\n",
    "\n",
    "Bonferroni correction is  of the most important step of the GWAS analysing to associate true positive SNPs with trait and prevent false positive (Type I error) type error (). But in our study is done first just Bonferroni correction but the result are associated more than expected SNPs with phenotype. In our cases stringent bonferroni correction are done with pvalue smaller than, number of SNPs multipled number of files to divided 0.05. The result of stringent bonferroni filter are saved (bonfe.r). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(tidyverse)\n",
    "library(fs)\n",
    "####this is bonferoni correction version more stringent \n",
    "Y <- list()\n",
    "csvfiles<-list.files(pattern = \"*.csv\")\n",
    "Y <- lapply(csvfiles, function(x) {\n",
    "  file <- read.csv(x)\n",
    "  return(file)\n",
    "})\n",
    "for (i in 1:length((csvfiles))){\n",
    "  R<-subset(Y[[i]],Y[[i]][[\"Pval\"]]<0.05/(2800000*738))\n",
    "  write.csv(R, file=paste( \"filtered_\",csvfiles[i],\".csv\", sep=\"\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e6d765",
   "metadata": {},
   "source": [
    "#### Gene Position files\n",
    "\n",
    "\n",
    "In this part, file contains gene start and stop position were added -50 kb to start position, +50 kb to stop posistion and saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0353b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####add values +-50kb to ara11\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ara11=pd.read_csv(\"ara11.csv\")\n",
    "###bu komut ile start -50kb cikarilir and stop +50kb eklenir\n",
    "ara11[\"Start\"]=ara11[\"Start\"]-50000\n",
    "ara11[\"Stop\"]=ara11[\"Stop\"]+50000\n",
    "print(ara11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c95eda",
   "metadata": {},
   "source": [
    "#### Second_gene name filter\n",
    "\n",
    "Second gene names are added as a new column called second_gene_name. It is important to determine second gene name to search cis hits for further steps. Second genes are define to be if it is an over cooccurance premature stop codon (SNPs) or not. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ce4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "small_gene=pd.DataFrame(filtered_files[\"file_name\"])\n",
    "small_gene\n",
    "second_gene_name=small_gene[\"file_name\"].str.split(\"_\",  n=1, expand=True)\n",
    "second_gene_name=second_gene_name[1].str.split(\".\",  n=1, expand=True)\n",
    "second_gene_name[\"second_gene_name\"]=second_gene_name[0]\n",
    "second_gene_name\n",
    "result=pd.concat([small_gene, second_gene_name[\"second_gene_name\"]], axis=1, ignore_index=True)\n",
    "result=result.set_axis([\"file_name\", \"second_gene_name\"], axis=1)\n",
    "#result.to_csv('/home/s417377/lastversion_gwas_analysis/Over_Occ/Small_gene.csv', index=False)\n",
    "result\n",
    "result=pd.read_csv('/home/s417377/lastversion_gwas_analysis/Over_Occ/trans_filtered_hit.csv')\n",
    "result1=pd.DataFrame(result[\"file_name\"])\n",
    "result2=pd.DataFrame(result[\"second_gene_name\"])\n",
    "first_gene_name=result[\"file_name\"].str.split(\"_\",  n=1, expand=True)\n",
    "first_gene_name\n",
    "first_gene_name[\"first_gene_name\"]=first_gene_name[0]\n",
    "first_gene_name\n",
    "result3=pd.concat([first_gene_name[\"first_gene_name\"],result2], axis=1, ignore_index=True)\n",
    "result4=pd.concat([result[\"file_name\"],result3], axis=1, ignore_index=True)\n",
    "result4\n",
    "result4=result4.set_axis([\"file_name\",\"first_gene_name\",\"second_gene_name\"], axis=1)\n",
    "#result4.to_csv('/home/s417377/lastversion_gwas_analysis/Over_Occ/first_second_gene.csv', index=False)\n",
    "result4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde206a",
   "metadata": {},
   "source": [
    "#### Number of Cis Hits\n",
    "\n",
    "Stringent bonferroni correction files are used to count cis and trans hits. Each stringent bonferroni corrected files are used. The second gene name is taken from the name of these files. Each SNPs position given in these files is valued according to the Start and Stop positions in the gene location file. If these SNPs positions are between the Start and Stop position, the SNPs at that position are called cis_hits, otherwise they are called trans hits. In this way, the number of cis hits for each file is subtracted from the total number of SNPs (hits) and the number of trans hits is found (cis_trans.r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "##count cis hits\n",
    "library(tidyverse)\n",
    "library(fs)\n",
    "setwd(\"~/lastversion_gwas_analysis/Over_Occ/stringent_correction_738/\")\n",
    "ara11<-read.csv(\"~/lastversion_gwas_analysis/ara11_50.csv\")\n",
    "\n",
    "small_gene<-read.csv(\"~/lastversion_gwas_analysis/Over_Occ/Small_gene.csv\")\n",
    "\n",
    "Y <- list()\n",
    "csvfiles<-list.files(pattern = \"*.csv\")\n",
    "Y <- lapply(csvfiles, function(x) {\n",
    "  file <- read.csv(x)\n",
    "  return(file)\n",
    "})\n",
    "\n",
    "new_list<-list()\n",
    "for (i in 1:length((csvfiles))){\n",
    "  b<-ara11[which(ara11$Gene==small_gene$second_gene_name[i]),]\n",
    "  c<-sum(b$Start<Y[[i]][[\"Pos\"]] & Y[[i]][[\"Pos\"]]<b$Stop)\n",
    "  new_list<-c(new_list,c)\n",
    "  new_list<-as.matrix(new_list, sep=\",\")\n",
    "  write.csv( new_list, \"small_gene_cis.csv\")\n",
    "}\n",
    "####change the folder name########\n",
    "folder = \"~/lastversion_gwas_analysis/PermGWAS_Scripts/deneme2//\"\n",
    "files <- list.files(folder,pattern = \"trans_.*.csv\",full.names = T) \n",
    "sapply(files,FUN=function(eachPath){ \n",
    "  file.rename(from=eachPath,to= sub(pattern=\"trans_\", paste0(\"\"),eachPath))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b352b283",
   "metadata": {},
   "source": [
    "#### Count cis and trans hits\n",
    "After counting cis hits, trans hits counted to sustraction of total hits to cis hits. New column added to the list as when the file contain cis hits it represented with 1, othervise 0.  New column added to the list as when the file contain trans hits it represented with 1, othervise 0. Last column added to the list as when both trans and cis hits founded in the same file, it represented with 1, othervise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4a943b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>second_gene_name</th>\n",
       "      <th>total_hit</th>\n",
       "      <th>cis_hits</th>\n",
       "      <th>trans_hits</th>\n",
       "      <th>cis_1</th>\n",
       "      <th>trans_1</th>\n",
       "      <th>cis_trans_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT1G04380_AT2G27340.csv</td>\n",
       "      <td>AT2G27340</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT1G04380_AT4G01925.csv</td>\n",
       "      <td>AT4G01925</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT1G04380_AT4G04220.csv</td>\n",
       "      <td>AT4G04220</td>\n",
       "      <td>125</td>\n",
       "      <td>117</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT1G04380_AT5G51795.csv</td>\n",
       "      <td>AT5G51795</td>\n",
       "      <td>175</td>\n",
       "      <td>41</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G11180_AT1G29710.csv</td>\n",
       "      <td>AT1G29710</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>AT5G66630_AT5G20450.csv</td>\n",
       "      <td>AT5G20450</td>\n",
       "      <td>139</td>\n",
       "      <td>101</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>AT5G66630_AT5G27110.csv</td>\n",
       "      <td>AT5G27110</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>AT5G66630_AT5G45150.csv</td>\n",
       "      <td>AT5G45150</td>\n",
       "      <td>385</td>\n",
       "      <td>115</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>AT5G66630_AT5G48350.csv</td>\n",
       "      <td>AT5G48350</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>AT5G66630_AT5G54020.csv</td>\n",
       "      <td>AT5G54020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>738 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name second_gene_name  total_hit  cis_hits  \\\n",
       "0    AT1G04380_AT2G27340.csv        AT2G27340         31         6   \n",
       "1    AT1G04380_AT4G01925.csv        AT4G01925         18        18   \n",
       "2    AT1G04380_AT4G04220.csv        AT4G04220        125       117   \n",
       "3    AT1G04380_AT5G51795.csv        AT5G51795        175        41   \n",
       "4    AT1G11180_AT1G29710.csv        AT1G29710         28        27   \n",
       "..                       ...              ...        ...       ...   \n",
       "733  AT5G66630_AT5G20450.csv        AT5G20450        139       101   \n",
       "734  AT5G66630_AT5G27110.csv        AT5G27110        250       250   \n",
       "735  AT5G66630_AT5G45150.csv        AT5G45150        385       115   \n",
       "736  AT5G66630_AT5G48350.csv        AT5G48350         56        29   \n",
       "737  AT5G66630_AT5G54020.csv        AT5G54020          0         0   \n",
       "\n",
       "     trans_hits  cis_1  trans_1  cis_trans_1  \n",
       "0            25      1        1          1.0  \n",
       "1             0      1        0          0.0  \n",
       "2             8      1        1          1.0  \n",
       "3           134      1        1          1.0  \n",
       "4             1      1        1          1.0  \n",
       "..          ...    ...      ...          ...  \n",
       "733          38      1        1          1.0  \n",
       "734           0      1        0          0.0  \n",
       "735         270      1        1          1.0  \n",
       "736          27      1        1          1.0  \n",
       "737           0      0        0          0.0  \n",
       "\n",
       "[738 rows x 8 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##add total SNPs hits, cis hits and trans hits as a new cloumns into result(Small_gene.csv) then sum only trans only cis and non hits\n",
    "os.chdir('~/lastversion_gwas_analysis/Over_Occ/stringent_correction_738/')\n",
    "total_hit = pd.DataFrame(columns=('file_name', 'total_hits'))\n",
    "\n",
    "for index,i in enumerate(os.listdir('.')):\n",
    "    total_hit.loc[index] = [i,len(pd.read_csv(i).index)]\n",
    "\n",
    "total_hit=total_hit.sort_values(\"file_name\")\n",
    "total_hit\n",
    "#total_hit.to_csv('/home/s417377/lastversion_gwas_analysis/Over_Occ/total_hit.csv', index=False)\n",
    "result=pd.read_csv(\"~/lastversion_gwas_analysis/Over_Occ/Small_gene.csv\")\n",
    "total_hits=pd.read_csv(\"~/lastversion_gwas_analysis/Over_Occ/total_hit.csv\")\n",
    "total_hits=total_hits[\"total_hits\"]\n",
    "result[\"total_hit\"]=total_hits\n",
    "\n",
    "cis_hits=pd.read_csv(\"~/lastversion_gwas_analysis/Over_Occ/stringent_correction_738/small_gene_cis.csv\")\n",
    "cis_hits=cis_hits[\"V1\"]\n",
    "cis_hits\n",
    "result[\"cis_hits\"]=cis_hits\n",
    "result\n",
    "result[\"trans_hits\"]=result[\"total_hit\"]-result[\"cis_hits\"]\n",
    "result\n",
    "##add new column if cis_hits>0 and trans_hits>0:\n",
    "result[\"cis_1\"]=np.where(result['cis_hits'] >0, 1, 0)\n",
    "result[\"trans_1\"]=np.where(result['trans_hits'] >0, 1, 0)\n",
    "result.loc[(result['cis_hits'] > 0)  & (result['trans_hits'] >0), 'cis_trans_1'] = 1\n",
    "result.loc[(result['cis_hits'] <= 0) | (result['trans_hits'] <=0), \"cis_trans_1\"] = 0\n",
    "#result.to_csv('/home/s417377/lastversion_gwas_analysis/Over_Occ/cis_trans_hit.csv', index=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b37ee5",
   "metadata": {},
   "source": [
    "#### Filter \n",
    "The gene AT2G15930 is not found on ara11 notation file that cause a problem to count allthe SNPs as a trans even some of them cis gits. It is inside tair10 file but all our analysis done for ara11 so file which contain as a second gene \"AT2G15930\" discarded to continue of this study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "99cefbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>second_gene_name</th>\n",
       "      <th>total_hit</th>\n",
       "      <th>cis_hits</th>\n",
       "      <th>trans_hits</th>\n",
       "      <th>cis_1</th>\n",
       "      <th>trans_1</th>\n",
       "      <th>cis_trans_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT1G04380_AT2G27340.csv</td>\n",
       "      <td>AT2G27340</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT1G04380_AT4G01925.csv</td>\n",
       "      <td>AT4G01925</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT1G04380_AT4G04220.csv</td>\n",
       "      <td>AT4G04220</td>\n",
       "      <td>125</td>\n",
       "      <td>117</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT1G04380_AT5G51795.csv</td>\n",
       "      <td>AT5G51795</td>\n",
       "      <td>175</td>\n",
       "      <td>41</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G11180_AT1G29710.csv</td>\n",
       "      <td>AT1G29710</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>AT5G66630_AT5G20450.csv</td>\n",
       "      <td>AT5G20450</td>\n",
       "      <td>139</td>\n",
       "      <td>101</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>AT5G66630_AT5G27110.csv</td>\n",
       "      <td>AT5G27110</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>AT5G66630_AT5G45150.csv</td>\n",
       "      <td>AT5G45150</td>\n",
       "      <td>385</td>\n",
       "      <td>115</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>AT5G66630_AT5G48350.csv</td>\n",
       "      <td>AT5G48350</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>AT5G66630_AT5G54020.csv</td>\n",
       "      <td>AT5G54020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name second_gene_name  total_hit  cis_hits  \\\n",
       "0    AT1G04380_AT2G27340.csv        AT2G27340         31         6   \n",
       "1    AT1G04380_AT4G01925.csv        AT4G01925         18        18   \n",
       "2    AT1G04380_AT4G04220.csv        AT4G04220        125       117   \n",
       "3    AT1G04380_AT5G51795.csv        AT5G51795        175        41   \n",
       "4    AT1G11180_AT1G29710.csv        AT1G29710         28        27   \n",
       "..                       ...              ...        ...       ...   \n",
       "733  AT5G66630_AT5G20450.csv        AT5G20450        139       101   \n",
       "734  AT5G66630_AT5G27110.csv        AT5G27110        250       250   \n",
       "735  AT5G66630_AT5G45150.csv        AT5G45150        385       115   \n",
       "736  AT5G66630_AT5G48350.csv        AT5G48350         56        29   \n",
       "737  AT5G66630_AT5G54020.csv        AT5G54020          0         0   \n",
       "\n",
       "     trans_hits  cis_1  trans_1  cis_trans_1  \n",
       "0            25      1        1          1.0  \n",
       "1             0      1        0          0.0  \n",
       "2             8      1        1          1.0  \n",
       "3           134      1        1          1.0  \n",
       "4             1      1        1          1.0  \n",
       "..          ...    ...      ...          ...  \n",
       "733          38      1        1          1.0  \n",
       "734           0      1        0          0.0  \n",
       "735         270      1        1          1.0  \n",
       "736          27      1        1          1.0  \n",
       "737           0      0        0          0.0  \n",
       "\n",
       "[724 rows x 8 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##files does not contain gene \"AT2G15930\" filtered to continue next steps\n",
    "filter=\"AT2G15930\"\n",
    "filtered_files=(result.loc[result['second_gene_name'] != \"AT2G15930\"])\n",
    "filtered_files=filtered_files.sort_values(\"file_name\")\n",
    "#filtered_files.to_csv('/home/s417377/lastversion_gwas_analysis/Over_Occ/cis_trans_filtered_hit.csv', index=False)\n",
    "filtered_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a68e6bc",
   "metadata": {},
   "source": [
    "#### Count hits \n",
    "In this section only cis, only trans, both trans and cis hits contains file, and non hit contain number of files are counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a983d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits           hit_sums\n",
      "-------------  -----------\n",
      "cis_only       201.0\n",
      "trans_only     11.0\n",
      "cis_trans_sum  478.0\n",
      "non_hit        34.0\n",
      "------------   -----------\n",
      "total_hit      724\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "result=pd.read_csv(\"~/lastversion_gwas_analysis/Over_Occ/cis_trans_filtered_hit.csv\")\n",
    "\n",
    "hit_sum_result=[]\n",
    "cis_sum=result.iloc[1:724, 5].sum()\n",
    "trans_sum=result.iloc[1:724, 6].sum()\n",
    "cis_trans_sum=result.iloc[1:724, 7].sum()\n",
    "only_cis=cis_sum-cis_trans_sum\n",
    "only_trans=trans_sum-cis_trans_sum\n",
    "non_hit=724-only_cis-only_trans-cis_trans_sum\n",
    "hit_sum_result=[\"cis_only\",only_cis],[\"trans_only\",only_trans],[\"cis_trans_sum\",cis_trans_sum],[\"non_hit\",non_hit],[\"------------\",\"-----------\"],[\"total_hit\",724]\n",
    "hit_sum_result\n",
    "\n",
    "col_names=[\"hits\",\"hit_sums\"]\n",
    "print(tabulate(hit_sum_result, headers=col_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c3b7e4",
   "metadata": {},
   "source": [
    "#### Filter Trans hits\n",
    "In this section only files contain trans hits are filtered and it will continue rest of the anlysis with these files. In GWAS analysis trans hits is important role on trait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d9083348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>second_gene_name</th>\n",
       "      <th>total_hit</th>\n",
       "      <th>cis_hits</th>\n",
       "      <th>trans_hits</th>\n",
       "      <th>cis_1</th>\n",
       "      <th>trans_1</th>\n",
       "      <th>cis_trans_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT1G04380_AT2G27340.csv</td>\n",
       "      <td>AT2G27340</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT1G04380_AT4G04220.csv</td>\n",
       "      <td>AT4G04220</td>\n",
       "      <td>125</td>\n",
       "      <td>117</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT1G04380_AT5G51795.csv</td>\n",
       "      <td>AT5G51795</td>\n",
       "      <td>175</td>\n",
       "      <td>41</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G11180_AT1G29710.csv</td>\n",
       "      <td>AT1G29710</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AT1G11180_AT1G65110.csv</td>\n",
       "      <td>AT1G65110</td>\n",
       "      <td>7992</td>\n",
       "      <td>63</td>\n",
       "      <td>7929</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>AT5G66630_AT2G04845.csv</td>\n",
       "      <td>AT2G04845</td>\n",
       "      <td>459</td>\n",
       "      <td>155</td>\n",
       "      <td>304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>AT5G66630_AT4G34460.csv</td>\n",
       "      <td>AT4G34460</td>\n",
       "      <td>328</td>\n",
       "      <td>272</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>AT5G66630_AT5G20450.csv</td>\n",
       "      <td>AT5G20450</td>\n",
       "      <td>139</td>\n",
       "      <td>101</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>AT5G66630_AT5G45150.csv</td>\n",
       "      <td>AT5G45150</td>\n",
       "      <td>385</td>\n",
       "      <td>115</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>AT5G66630_AT5G48350.csv</td>\n",
       "      <td>AT5G48350</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name second_gene_name  total_hit  cis_hits  \\\n",
       "0    AT1G04380_AT2G27340.csv        AT2G27340         31         6   \n",
       "2    AT1G04380_AT4G04220.csv        AT4G04220        125       117   \n",
       "3    AT1G04380_AT5G51795.csv        AT5G51795        175        41   \n",
       "4    AT1G11180_AT1G29710.csv        AT1G29710         28        27   \n",
       "5    AT1G11180_AT1G65110.csv        AT1G65110       7992        63   \n",
       "..                       ...              ...        ...       ...   \n",
       "716  AT5G66630_AT2G04845.csv        AT2G04845        459       155   \n",
       "718  AT5G66630_AT4G34460.csv        AT4G34460        328       272   \n",
       "719  AT5G66630_AT5G20450.csv        AT5G20450        139       101   \n",
       "721  AT5G66630_AT5G45150.csv        AT5G45150        385       115   \n",
       "722  AT5G66630_AT5G48350.csv        AT5G48350         56        29   \n",
       "\n",
       "     trans_hits  cis_1  trans_1  cis_trans_1  \n",
       "0            25      1        1          1.0  \n",
       "2             8      1        1          1.0  \n",
       "3           134      1        1          1.0  \n",
       "4             1      1        1          1.0  \n",
       "5          7929      1        1          1.0  \n",
       "..          ...    ...      ...          ...  \n",
       "716         304      1        1          1.0  \n",
       "718          56      1        1          1.0  \n",
       "719          38      1        1          1.0  \n",
       "721         270      1        1          1.0  \n",
       "722          27      1        1          1.0  \n",
       "\n",
       "[490 rows x 8 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###filter trans files \n",
    "trans_files=(result.loc[result['trans_1'] == 1])\n",
    "trans_files.to_csv('~/lastversion_gwas_analysis/Over_Occ/trans_filtered_hit.csv', index=False)\n",
    "trans_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4868a85",
   "metadata": {},
   "source": [
    "### Cis hits are removed from files\n",
    "After filtering trans files, still some of the files contain cis hits inside. With this step rest of the cis hits are removed from files (cis_removed.r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a464fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "####filter stringent result files, only contain trans hits\n",
    "####filter stringent result files, only contain trans hits\n",
    "setwd(\"~/lastversion_gwas_analysis/Over_Occ/\")\n",
    "small_gene<-read.csv(\"~/lastversion_gwas_analysis/Over_Occ/trans_filtered_hit.csv\")\n",
    "ara11<-read.csv(\"~/lastversion_gwas_analysis/ara11_50.csv\")\n",
    "\n",
    "Y <- list()\n",
    "csvfiles<-list.files(pattern = \"*.csv\")\n",
    "Y <- lapply(csvfiles, function(x) {\n",
    "  file <- read.csv(x)\n",
    "  return(file)\n",
    "})\n",
    "for (i in 1:length((csvfiles))){\n",
    "  b<-ara11[which(ara11$Gene==S$second_gene_name[i]),]\n",
    "  trials<-subset(Y[[i]],!(b$Start<Y[[i]][[\"Pos\"]] & Y[[i]][[\"Pos\"]]<b$Stop))\n",
    "  write.csv(trials, file=paste( \"filtered_\",csvfiles[i],\".csv\", sep=\"\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c906dc",
   "metadata": {},
   "source": [
    "### Count number of trans genes, \n",
    "SNPs in files containing trans hits are determined to belong to which genes, and added to the trans_gene list. For this, it is found on which gene the SNPs in the trans files are located in the ara11_10 file, which contains all the SNPs. In this way, if there is a gene corresponding to all SNPs, those genes are added to the list. It is found in the genes in the 10 kb window and added to the list (count_trans_genes.r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c810ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "##filtering overlapping genes in 10 kb window\n",
    "library(tidyverse)\n",
    "SNPs<-read.csv('~/lastversion_gwas_analysis/SNPs_11_10.csv')\n",
    "ara11<-read.csv(\"~/lastversion_gwas_analysis/ara11_50.csv\")\n",
    "small_gene<-pd.read_csv(\"~/lastversion_gwas_analysis/Over_Occ/Small_gene.csv\")\n",
    "\n",
    "A<-read.csv('~/lastversion_gwas_analysis/f95_bonf/trans_filtered_hits.csv')\n",
    "S<-A[,1:5]\n",
    "S$gens_trans<-NA\n",
    "S$gens_trans_10kb<-NA\n",
    "\n",
    "####apply all files see if it is any pattern\n",
    "setwd(\"~/lastversion_gwas_analysis/Over_Occ/trans_hits/\")\n",
    "Trans <- list()\n",
    "csvfiles<-list.files(pattern = \"*filtered_\")\n",
    "Trans <- lapply(csvfiles, function(x) {\n",
    "  file <- read.csv(x)\n",
    "  return(file)\n",
    "})\n",
    "\n",
    "for (i in 1:length((csvfiles))){\n",
    "  Z<-merge(Trans[[i]][,c(4,9)],SNPs[,c(5,17,18)],by='SNP')\n",
    "  S[i,6]<-paste(as.character(na.omit(unique(Z$gene_ara11))),collapse=',')\n",
    "  S[i,7]<-paste(unique(unlist(strsplit(as.character(na.omit(unique(Z$genes_10kb__ara11))),split=','))),collapse=',')\n",
    "  cat(i,'\\n')\n",
    "}\n",
    "\n",
    "a<-nchar(gsub('[^,]','',S$gens_trans))+1\n",
    "df<-as.data.frame(a)\n",
    "S['gene_count']<-NA\n",
    "S['gene_count']<-df\n",
    "write.csv(S, \"~/lastversion_gwas_analysis/overlapping_result/overlapping_genes.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bf82b2",
   "metadata": {},
   "source": [
    "### Duplicated Files\n",
    "In this section, compared if the files G1_G2 and G2_G1 has a comman trans genes, for this first new csv files created and inside the file combination of all G1_G2 and G2_G1 are put same row after that detected trans file duplicated (overlap_genew.r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d789087",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "##In this section, compared if the files G1_G2 and G2_G1 has a comman trans genes, for this first new csv files created \n",
    "#and inside the file combination of all G1_G2 and G2_G1 are put same row \n",
    "#after that detected \n",
    "#trans file duplicated \n",
    "aa<- read.csv(\"~/lastversion_gwas_analysis/Over_Occ/first_second_gene.csv\")\n",
    "new_list<-vector()\n",
    "for(i in 1:nrow(aa)){\n",
    "  b<-aa[which(aa$first_gene_name==aa$second_gene_name[i]&aa$second_gene_name==aa$first_gene_name[i]),]\n",
    "  d<- merge(b$file_name , aa$file_name[i])\n",
    "  new_list<-c(new_list,d)\n",
    "  new_list<-as.matrix(new_list, sep=\",\")\n",
    "  new<-as.data.frame(new_list)\n",
    "}\n",
    "####duplicated_trans_file\n",
    "new$duplicated = as.character(new$duplicated)\n",
    "new_list<-as.numeric(new_list)\n",
    "write.table(new, \"~/lastversion_gwas_analysis/Over_Occ/duplicated_trans_files.csv\")\n",
    "colnames(new)<-c(\"duplicated\")\n",
    "row_odd<-seq_len(nrow(new_list)) %% 2\n",
    "data_row_odd<- as.data.frame(data_frame(new_list[row_odd == 1, ]))\n",
    "row_even<-seq_len(nrow(new_list)) %% 2\n",
    "data_even_odd<- as.data.frame(data_frame(new_list[row_odd == 0, ] ) )\n",
    "combine<-data_frame(data_even_odd,data_row_odd)\n",
    "data_even_odd$`new_list[row_odd == 0, ]`=as.character(data_even_odd$`new_list[row_odd == 0, ]`)\n",
    "data_row_odd$`new_list[row_odd == 1, ]`=as.character(data_row_odd$`new_list[row_odd == 1, ]`)\n",
    "colnames(combine)<-c(\"file_1\", \"file_2\")\n",
    "write.csv(combine, \"~/lastversion_gwas_analysis/Over_Occ/dup_trans_files.csv\")\n",
    "#######trans file daki genler ayni mi degil mi?\n",
    "overlpp<-read.csv(\"overlapping_genes.csv\")\n",
    "\n",
    "new_list<-vector()\n",
    "for(i in 1:nrow(overlpp)){\n",
    "   a<-overlpp[which(combine$file_1[i]==overlpp$file_name),]\n",
    "   b<-overlpp[which(combine$file_2[i]==overlpp$file_name),]\n",
    "   d<-overlpp[a$gens_trans[i]==b$gens_trans,]\n",
    "   dd<- merge(d$gens_trans , a$file_name[i])\n",
    "   new_list<-c(new_list,d)\n",
    "   new_list<-as.matrix(new_list, sep=\",\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4062738",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(tidyverse)\n",
    "library(fs)\n",
    "\n",
    "dup_trans_genes<-read.csv(\"~/lastversion_gwas_analysis/Over_Occ/first_second_gene.csv\")\n",
    "#trans file duplicated \n",
    "new_list<-list()\n",
    "for(i in 1:nrow(aa)){\n",
    "  b<-aa[which(aa$first_gene_name==aa$second_gene_name[i]&aa$second_gene_name==aa$first_gene_name[i]),]\n",
    "  d<- merge(b$file_name , aa$file_name[i])\n",
    "  new_list<-c(new_list,d)\n",
    "  new_list<-as.matrix(new_list, sep=\",\")\n",
    "}\n",
    "new$duplicated = as.character(new$duplicated)\n",
    "new_list<-as.numeric(new_list)\n",
    "write.table(new, \"~/lastversion_gwas_analysis/Over_Occ/duplicated_trans_files.csv\")\n",
    "colnames(new)<-c(\"duplicated\")\n",
    "row_odd<-seq_len(nrow(new_list)) %% 2\n",
    "data_row_odd<- as.data.frame(data_frame(new_list[row_odd == 1, ]))\n",
    "row_even<-seq_len(nrow(new_list)) %% 2\n",
    "data_even_odd<- as.data.frame(data_frame(new_list[row_odd == 0, ] ) )\n",
    "combine<-data_frame(data_even_odd,data_row_odd)\n",
    "data_even_odd$`new_list[row_odd == 0, ]`=as.character(data_even_odd$`new_list[row_odd == 0, ]`)\n",
    "data_row_odd$`new_list[row_odd == 1, ]`=as.character(data_row_odd$`new_list[row_odd == 1, ]`)\n",
    "colnames(combine)<-c(\"file_1\", \"file_2\")\n",
    "write.csv(combine, \"~/lastversion_gwas_analysis/Over_Occ/dup_trans_files.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077fdba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "overlpp<-read.csv(\"~/lastversion_gwas_analysis/overlapping_result/perm_overlapping_genes.csv\")\n",
    "combine<-read.csv(\"~/lastversion_gwas_analysis/PermGWAS_Scripts/dupli_trans_file_names.csv\")\n",
    "for(i in 1:nrow(overlpp)){\n",
    "  a<-overlpp[which(combine$file_1[i]==overlpp$file_name),]\n",
    "  b<-overlpp[which(combine$file_2[i]==overlpp$file_name),]\n",
    "  w<-unlist(strsplit(a$gens_trans, \",\"))\n",
    "  w2<-unlist(strsplit(b$gens_trans, \",\"))\n",
    "  da<-intersect(w,w2)\n",
    "  combine[i,4]<-paste(as.character(na.omit(da)),collapse=',')\n",
    "  #######  d<- merge(da$gens_trans , da$gens_trans)\n",
    "  #######  new_list<-c(new_list,d)\n",
    "  #######  new_list<-as.matrix(new_list, sep=\",\")\n",
    "}\n",
    "write.csv(Y, \"~/lastversion_gwas_analysis/overlapping_result/duplicated_overlapping_genes.csv\", row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "dfi.convert('~/GWAS_Python_R_code.ipynb',\n",
    "                to='pdf',\n",
    "                use='latex',\n",
    "                center_df=True,\n",
    "                max_rows=30,\n",
    "                max_cols=10,\n",
    "                execute=False,\n",
    "                save_notebook=False,\n",
    "                limit=None,\n",
    "                document_name=None,\n",
    "                table_conversion='chrome'\n",
    "                #chrome_path=None,\n",
    "                #latex_command=None,\n",
    "                #output_dir=None,\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
